{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zilavalencia/ChungaraVZila-IA-SIS420/blob/main/Laboratorios/Laboratorio02/pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LABORATORIO 2 REDES NEURONALES USANDO PYTORCH\n",
        "Estudiantes:\n",
        "\n",
        "Portillo Mercado Daniela\n",
        "\n",
        "Chungara Valencia Zila\n",
        "\n",
        "Rodas Palacios Max Jherzon\n",
        "\n",
        "Link dataset: https://www.kaggle.com/datasets/jvageesh11/simpsons-mnist\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YkKSEgN4mVlL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DATASET:\n",
        "\n",
        "Presenta imágenes de 28x28 de personajes de Los Simpson\n",
        "Formato RGB\n",
        "Incluye 8000 muestras de entrenamiento y 2000 muestras de prueba  \n",
        "10 clases de personajes."
      ],
      "metadata": {
        "id": "8QR4VTeinJwy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwWkTpadQb81"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Definir transformaciones para las imágenes\n",
        "# Transformación para prueba - redimensionar a 28x28 y convertir a tensor\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),  # Redimensionar todas las imágenes a 28x28\n",
        "    transforms.ToTensor(),        # Convertir a tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizar RGB\n",
        "])\n",
        "\n",
        "# Transformación para entrenamiento - incluye aumentación de datos\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),  # Redimensionar todas las imágenes a 28x28\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # 50% de probabilidad de volteo\n",
        "    transforms.ToTensor(),        # Convertir a tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizar RGB\n",
        "])\n",
        "\n",
        "# Cargar los datasets\n",
        "def load_datasets(data_dir):\n",
        "    train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train2'), transform=transform_train)\n",
        "    test_dataset = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=transform)\n",
        "\n",
        "    # Crear dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader, train_dataset, test_dataset\n",
        "\n",
        "# Definir el modelo MLP\n",
        "class MLP(nn.Module):\n",
        "    def init(self, input_size, hidden_sizes, num_classes):\n",
        "        super(MLP, self).init()\n",
        "\n",
        "        # Capa de entrada\n",
        "        layers = [nn.Flatten()]\n",
        "\n",
        "        # Agregar capas ocultas\n",
        "        prev_size = input_size\n",
        "        for hidden_size in hidden_sizes:\n",
        "            layers.append(nn.Linear(prev_size, hidden_size))\n",
        "            layers.append(nn.ReLU())\n",
        "            prev_size = hidden_size\n",
        "\n",
        "        # Capa de salida\n",
        "        layers.append(nn.Linear(prev_size, num_classes))\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Función para entrenar el modelo\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs):\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    # Bucle de entrenamiento\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            # Mover datos a GPU si está disponible\n",
        "            if torch.cuda.is_available():\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward y optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Estadísticas\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Calcular pérdida y precisión de entrenamiento\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_acc = 100 * correct / total\n",
        "        train_losses.append(epoch_loss)\n",
        "        train_accuracies.append(epoch_acc)\n",
        "\n",
        "        # Evaluar en el conjunto de prueba\n",
        "        test_loss, test_acc = evaluate_model(model, test_loader, criterion)\n",
        "        test_losses.append(test_loss)\n",
        "        test_accuracies.append(test_acc)\n",
        "\n",
        "        print(f'Época {epoch+1}/{num_epochs}, '\n",
        "              f'Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%, '\n",
        "              f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
        "        print(f'Época {epoch+1}/{num_epochs}, Train: {epoch_acc:.2f}% ({correct}/{total}), Test: {test_acc:.2f}%, Train Loss: {epoch_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
        "\n",
        "        # Verificar si cumplimos con los criterios (precisión > 90% y pérdida < 0.05)\n",
        "        if test_acc > 90 and test_loss < 0.05:\n",
        "            print(f'¡Criterios cumplidos en la época {epoch+1}!')\n",
        "            break\n",
        "\n",
        "    return train_losses, test_losses, train_accuracies, test_accuracies\n",
        "\n",
        "# Función para evaluar el modelo\n",
        "def evaluate_model(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            if torch.cuda.is_available():\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return running_loss / len(dataloader), 100 * correct / total\n",
        "\n",
        "# Función para probar el modelo con imágenes aleatorias\n",
        "def test_random_images(model, test_dataset, num_images=10):\n",
        "    # Obtener índices aleatorios\n",
        "    indices = random.sample(range(len(test_dataset)), num_images)\n",
        "\n",
        "    # Configurar el modelo en modo evaluación\n",
        "    model.eval()\n",
        "\n",
        "    # Configurar la figura para mostrar imágenes\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, idx in enumerate(indices):\n",
        "            # Obtener imagen y etiqueta real\n",
        "            image, true_label = test_dataset[idx]\n",
        "\n",
        "            # Obtener la predicción\n",
        "            if torch.cuda.is_available():\n",
        "                image = image.cuda()\n",
        "\n",
        "            output = model(image.unsqueeze(0))\n",
        "            _, predicted = torch.max(output, 1)\n",
        "\n",
        "            # Preparar imagen para mostrar\n",
        "            image = image.cpu().numpy().transpose(1, 2, 0)  # Cambiar de [C,H,W] a [H,W,C] para RGB\n",
        "            image = (image * 0.5 + 0.5)  # Desnormalizar\n",
        "            image = image.clip(0, 1)  # Asegurar valores en rango [0,1]\n",
        "\n",
        "            # Mostrar imagen y predicciones\n",
        "            axes[i].imshow(image)\n",
        "            axes[i].set_title(f'Pred: {test_dataset.classes[predicted.item()]}\\nTrue: {test_dataset.classes[true_label]}')\n",
        "            axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return indices\n",
        "\n",
        "# Función principal\n",
        "def main(data_dir, hidden_sizes=[64], num_epochs=50):\n",
        "    # Cargar datos\n",
        "    train_loader, test_loader, train_dataset, test_dataset = load_datasets(data_dir)\n",
        "\n",
        "    # Obtener número de clases\n",
        "    num_classes = len(train_dataset.classes)\n",
        "    print(f\"Clases detectadas: {train_dataset.classes}\")\n",
        "\n",
        "    # Definir el modelo\n",
        "    input_size = 3 * 28 * 28  # RGB 28x28 (3 canales)\n",
        "    model = MLP(input_size, hidden_sizes, num_classes)\n",
        "\n",
        "    # Mover el modelo a GPU si está disponible\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "        print(\"Usando GPU para el entrenamiento\")\n",
        "    else:\n",
        "        print(\"Usando CPU para el entrenamiento\")\n",
        "\n",
        "    # Definir pérdida y optimizador\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    train_losses, test_losses, train_accuracies, test_accuracies = train_model(\n",
        "        model, train_loader, test_loader, criterion, optimizer, num_epochs\n",
        "    )\n",
        "\n",
        "    # Visualizar las pérdidas y precisiones\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(test_losses, label='Test Loss')\n",
        "    plt.title('Pérdida por Época')\n",
        "    plt.xlabel('Época')\n",
        "    plt.ylabel('Pérdida')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accuracies, label='Train Accuracy')\n",
        "    plt.plot(test_accuracies, label='Test Accuracy')\n",
        "    plt.title('Precisión por Época')\n",
        "    plt.xlabel('Época')\n",
        "    plt.ylabel('Precisión (%)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Probar el modelo con imágenes aleatorias\n",
        "    print(\"\\nProbando el modelo con 10 imágenes aleatorias:\")\n",
        "    indices = test_random_images(model, test_dataset)\n",
        "\n",
        "    # Guardar el modelo\n",
        "    torch.save(model.state_dict(), 'mlp_model.pth')\n",
        "    print(\"Modelo guardado como 'mlp_model.pth'\")\n",
        "\n",
        "# Ejecutar el programa\n",
        "if name == \"main\":\n",
        "    # Reemplazar con la ruta a tu directorio de datos\n",
        "    data_dir = \"/home/n3st/Documents/Python/fotos\"  # Ajusta esta ruta a tu directorio de datos\n",
        "\n",
        "    # Puedes ajustar la arquitectura de la red neural aquí\n",
        "    hidden_sizes = [512, 256, 128, 64]  # Cuatro capas ocultas\n",
        "\n",
        "    main(data_dir, hidden_sizes, num_epochs=100)"
      ]
    }
  ]
}